hoodsTracts$mapname <- as.character(hoodsTracts$mapname)
str(hoodsTracts)
census_pull <- function(year,vars,stateFICS,county) {
final_url <- paste0("https://api.census.gov/data/",year,"/acs/acs5?get=",vars
,"&for=tract:*&in=state:",stateFICS,"&in=county:",county,"&key=",censusKey)
dat <- fromJSON(file = final_url)
d = ldply(dat)
colnames(d) <- d[1, ] # the first row will be the header
d = d[-1, ]          # removing the first row.
d <- unite(d,"GEOID10", c("state","county","tract"),sep="",remove=TRUE)
colNames <- colnames(d)
d[,colNames]<-lapply(d[,colNames],as.numeric)
d$GEOID10 <- as.factor(d$GEOID10)
d %>%
left_join(hoodsTracts,d,by='GEOID10')
group_by('mapname') %>%
summarise(pop = sum(B17001_001E, na.rm = TRUE),
pov = sum(B17001_002E, na.rm = TRUE),
hhs = sum(B25003_001E, na.rm = TRUE),
hom = sum(B25003_002E, na.rm=TRUE))
}
test <- census_pull(year=2016
,vars = 'B17001_001E,B17001_002E,B25003_001E,B25003_002E'
,stateFICS = 42
,county = 101)
census_pull <- function(year,vars,stateFICS,county) {
final_url <- paste0("https://api.census.gov/data/",year,"/acs/acs5?get=",vars
,"&for=tract:*&in=state:",stateFICS,"&in=county:",county,"&key=",censusKey)
dat <- fromJSON(file = final_url)
d = ldply(dat)
colnames(d) <- d[1, ] # the first row will be the header
d = d[-1, ]          # removing the first row.
d <- unite(d,"GEOID10", c("state","county","tract"),sep="",remove=TRUE)
colNames <- colnames(d)
d[,colNames]<-lapply(d[,colNames],as.numeric)
d$GEOID10 <- as.factor(d$GEOID10)
d %>%
left_join(hoodsTracts,d,by='GEOID10')
group_by(mapname) %>%
summarise(pop = sum(B17001_001E, na.rm = TRUE),
pov = sum(B17001_002E, na.rm = TRUE),
hhs = sum(B25003_001E, na.rm = TRUE),
hom = sum(B25003_002E, na.rm=TRUE))
}
test <- census_pull(year=2016
,vars = 'B17001_001E,B17001_002E,B25003_001E,B25003_002E'
,stateFICS = 42
,county = 101)
census_pull <- function(year,vars,stateFICS,county) {
final_url <- paste0("https://api.census.gov/data/",year,"/acs/acs5?get=",vars
,"&for=tract:*&in=state:",stateFICS,"&in=county:",county,"&key=",censusKey)
dat <- fromJSON(file = final_url)
d = ldply(dat)
colnames(d) <- d[1, ] # the first row will be the header
d = d[-1, ]          # removing the first row.
d <- unite(d,"GEOID10", c("state","county","tract"),sep="",remove=TRUE)
colNames <- colnames(d)
d[,colNames]<-lapply(d[,colNames],as.numeric)
d$GEOID10 <- as.factor(d$GEOID10)
d %>%
left_join(hoodsTracts,d,by='GEOID10')
group_by(mapname) %>%
summarise(pop = sum(B17001_001E, na.rm = TRUE),
pov = sum(B17001_002E, na.rm = TRUE),
hhs = sum(B25003_001E, na.rm = TRUE),
hom = sum(B25003_002E, na.rm=TRUE))
d
}
test <- census_pull(year=2016
,vars = 'B17001_001E,B17001_002E,B25003_001E,B25003_002E'
,stateFICS = 42
,county = 101)
census_pull <- function(year,vars,stateFICS,county) {
final_url <- paste0("https://api.census.gov/data/",year,"/acs/acs5?get=",vars
,"&for=tract:*&in=state:",stateFICS,"&in=county:",county,"&key=",censusKey)
dat <- fromJSON(file = final_url)
d = ldply(dat)
colnames(d) <- d[1, ] # the first row will be the header
d = d[-1, ]          # removing the first row.
d <- unite(d,"GEOID10", c("state","county","tract"),sep="",remove=TRUE)
colNames <- colnames(d)
d[,colNames]<-lapply(d[,colNames],as.numeric)
d$GEOID10 <- as.factor(d$GEOID10)
d %>%
left_join(hoodsTracts,d,by='GEOID10') %>%
group_by(mapname) %>%
summarise(pop = sum(B17001_001E, na.rm = TRUE),
pov = sum(B17001_002E, na.rm = TRUE),
hhs = sum(B25003_001E, na.rm = TRUE),
hom = sum(B25003_002E, na.rm=TRUE))
d
}
test <- census_pull(year=2016
,vars = 'B17001_001E,B17001_002E,B25003_001E,B25003_002E'
,stateFICS = 42
,county = 101)
View(test)
census_pull <- function(year,vars,stateFICS,county) {
final_url <- paste0("https://api.census.gov/data/",year,"/acs/acs5?get=",vars
,"&for=tract:*&in=state:",stateFICS,"&in=county:",county,"&key=",censusKey)
dat <- fromJSON(file = final_url)
d = ldply(dat)
colnames(d) <- d[1, ] # the first row will be the header
d = d[-1, ]          # removing the first row.
d <- unite(d,"GEOID10", c("state","county","tract"),sep="",remove=TRUE)
colNames <- colnames(d)
d[,colNames]<-lapply(d[,colNames],as.numeric)
d$GEOID10 <- as.factor(d$GEOID10)
d %>%
left_join(hoodsTracts,d,by='GEOID10') %>%
group_by(mapname) %>%
summarise(pop = sum(B17001_001E, na.rm = TRUE),
pov = sum(B17001_002E, na.rm = TRUE),
hhs = sum(B25003_001E, na.rm = TRUE),
hom = sum(B25003_002E, na.rm=TRUE))
}
test <- census_pull(year=2016
,vars = 'B17001_001E,B17001_002E,B25003_001E,B25003_002E'
,stateFICS = 42
,county = 101)
View(test)
View(d)
census_pull <- function(year,vars,stateFICS,county) {
final_url <- paste0("https://api.census.gov/data/",year,"/acs/acs5?get=",vars
,"&for=tract:*&in=state:",stateFICS,"&in=county:",county,"&key=",censusKey)
dat <- fromJSON(file = final_url)
d = ldply(dat)
colnames(d) <- d[1, ] # the first row will be the header
d = d[-1, ]          # removing the first row.
d <- unite(d,"GEOID10", c("state","county","tract"),sep="",remove=TRUE)
colNames <- colnames(d)
d[,colNames]<-lapply(d[,colNames],as.numeric)
d$GEOID10 <- as.factor(d$GEOID10)
d %>%
left_join(hoodsTracts,d,by='GEOID10')
}
test <- census_pull(year=2016
,vars = 'B17001_001E,B17001_002E,B25003_001E,B25003_002E'
,stateFICS = 42
,county = 101)
View(test)
combo3 <- ddply(test, c("mapname"), summarise,
pop = sum(B17001_001E, na.rm = TRUE),
pov = sum(B17001_002E, na.rm = TRUE),
hhs = sum(B25003_001E, na.rm = TRUE),
hom = sum(B25003_002E,na.rm=TRUE))
View(combo3)
combo3$povPct <- ifelse(combo3$pop != 0, as.numeric(round((combo3$pov / combo3$pop) * 100,1)), NA)
combo3$homPct <- ifelse(combo3$hhs != 0, as.numeric(round((combo3$hom / combo3$hhs) * 100,1)), NA)
polyData <- left_join(x=hoods,y=combo3,by="mapname")
polyData <- subset(polyData,select = -c(cartodb_id,created_at,updated_at,name,listname))
school_pull('PA','Philadelphia','High Schools')
school_pull <- function(stateAbbrev,city,level) {
schoolURL <- paste0("https://api.greatschools.org/search/schools?key=",
greatSchoolsKey,"&state=",stateAbbrev,"&q=",city,"&sort=alpha&levelCode="
,level)
schoolDat <- fromJSON(file = schoolURL)
}
school_pull('PA','Philadelphia','High Schools')
greatSchoolsKey <- "4c6cbbb25c5ad456271f0b1e1b8fe9d4"
school_pull <- function(stateAbbrev,city,level) {
schoolURL <- paste0("https://api.greatschools.org/search/schools?key=",
greatSchoolsKey,"&state=",stateAbbrev,"&q=",city,"&sort=alpha&levelCode="
,level)
schoolDat <- fromJSON(file = schoolURL)
}
school_pull('PA','Philadelphia','High Schools')
school_pull <- function(stateAbbrev,city,level) {
schoolURL <- paste0("https://api.greatschools.org/search/schools?key=",
greatSchoolsKey,"&state=",stateAbbrev,"&q=",city,"&sort=alpha&levelCode="
,level,"-schools")
schoolDat <- fromJSON(file = schoolURL)
}
school_pull('PA','Philadelphia','High')
school_pull <- function(stateAbbrev) {
schoolURL <- paste0("https://api.greatschools.org/school/tests/"
,stateAbbrev,"?key=",greatSchoolsKey
)
schoolDat <- fromJSON(file = schoolURL)
}
school_pull('PA')
schoolURL <- paste0("https://api.greatschools.org/school/tests/"
,stateAbbrev,"/?key=",greatSchoolsKey
)
school_pull <- function(stateAbbrev) {
schoolURL <- paste0("https://api.greatschools.org/school/tests/"
,stateAbbrev,"/?key=",greatSchoolsKey
)
schoolDat <- fromJSON(file = schoolURL)
}
school_pull('PA')
school_pull <- function(stateAbbrev,city) {
schoolURL <- paste0("https://api.greatschools.org/schools/"
,stateAbbrev,"/",city,"?key=",greatSchoolsKey)
schoolDat <- fromJSON(file = schoolURL)
}
school_pull('PA','Philadelphia')
school_pull <- function(stateAbbrev,city) {
schoolURL <- paste0("https://api.greatschools.org/schools/"
,stateAbbrev,"/",city,"?key=",greatSchoolsKey)
fromJSON(file = schoolURL)
}
school_pull('PA','Philadelphia')
install.packages('xml2')
install.packages('xmltools')
devtools::install_github('dantonnoriega/xmltools')
install.packages(c("acs", "arm", "backports", "BH", "bindr", "bindrcpp", "broom", "car", "carData", "caret", "censusapi", "checkmate", "coin", "CORElearn", "corrplot", "curl", "data.table", "DBI", "ddalpha", "devtools", "digest", "dplyr", "DRR", "DT", "effects", "forcats", "foreach", "foreign", "Formula", "geojsonio", "geosphere", "ggeffects", "ggthemes", "git2r", "glmmTMB", "glue", "haven", "hexbin", "Hmisc", "hms", "htmlTable", "htmlwidgets", "httpuv", "iterators", "kernlab", "knitr", "lava", "lazyeval", "leaflet", "lme4", "lmtest", "lubridate", "mapproj", "maps", "mlogit", "multcomp", "mvtnorm", "openssl", "pastecs", "pdftools", "plogr", "popbio", "prediction", "pROC", "prodlim", "pscl", "psych", "purrr", "pwr", "quantreg", "randomForest", "raster", "Rcpp", "RcppEigen", "RCurl", "readxl", "recipes", "reshape2", "rgdal", "rgeos", "rJava", "rjson", "rlang", "rmarkdown", "robustbase", "rprojroot", "RSocrata", "selectr", "sf", "sjlabelled", "sjmisc", "sjPlot", "sjstats", "sourcetools", "sp", "stargazer", "stringdist", "stringi", "stringr", "survey", "survival", "testthat", "tibble", "tidycensus", "tidyr", "tidyselect", "tidyverse", "tigris", "timeDate", "tm", "TMB", "units", "vcd", "viridis", "viridisLite", "withr", "XML", "yaml", "zoo"))
install.packages('devtools') #assuming it is not already installed
library(devtools)
install_github('andreacirilloac/updateR')
library(xmltools)
devtools::install_github('dantonnoriega/xmltools')
devtools::install_github('dantonnoriega/xmltools')
library(sf)
library(plyr)
install.packages('sf','plyr','dplyr','rjson','tidyr','sp','rgdal','geojsonio'
,'devtools')
cancel
install.packages('sf')
install.packages('sf')
library(sf)
library(sf)
update.packages()
version
packageStatus()
library(sf)
library(plyr)
library(dplyr)
library(rjson)
library(tidyr)
install.packages('sf')
library(sf)
install.packages('devtools')
library(devtools)
install_github('andreacirilloac/updateR')
library(updateR)
updateR(admin_password = 'Tw33tys!')
library(sf)
install.packages(sf)
install.packages('sf')
library(plyr)
library(dplyr)
library(rjson)
library(tidyr)
library(sp)
library(rgdal)
library(geojsonio)
devtools::install_github('dantonnoriega/xmltools')
library(xmltools)
censusKey <- "4d92e5c53d5b7046bae0b72874aceed0fde3e0b4"
greatSchoolsKey <- "4c6cbbb25c5ad456271f0b1e1b8fe9d4"
hoods <- st_read("https://raw.githubusercontent.com/alisanroman/philly-hoods/master/data/Neighborhoods_Philadelphia.geojson")
library(sf)
install.packages("sf")
library(rgdal)
library(sf)
library(rgdal)
install.packages('rgdal')
library(rgdal)
library(sf)
library(plyr)
library(dplyr)
library(rjson)
install.packages('rjson')
library(rjson)
library(tidyr)
library(sp)
library(geojsonio)
install.packages('geojsonio')
install.packages("rgdal", repos = "http://cran.us.r-project.org", type = "source")
install.packages("rgdal", repos = "http://cran.us.r-project.org", type = "source")
library(rgdal)
update.packages('rgdal')
library(rgdal)
library(plyr)
library(dplyr)
library(rjson)
library(tidyr)
library(sp)
library(geojsonio)
library(sf)
install.packages('sf')
# Global options
setwd('/Users/amsr/Documents/GitHub/qapScoring-Final/data')
options(stringsAsFactors = FALSE)
library(units)
library(tidyverse)
library(sf)
library(mapview)
# Read in all files
bslStations <- st_read("SEPTA__Broad_Street_Line_Stations.geojson")
busStations <- st_read("SEPTA__Bus_Stops.geojson")
mflStations <- st_read("SEPTA__MarketFrankford_Line_Stations.geojson")
norStations <- st_read("SEPTA__Norristown_Highspeed_Line_Stations.geojson")
trolStations<- st_read("SEPTA__Trolley_Stops.geojson")
rrStations <- st_read("SEPTA_Regional_Rail_Stations.geojson")
colnames(bslStations)
allStations <- st_union(bslStations[,c(1:4,43:45)]
,mflStations[,c(1:4,43:45)])
allStations <- st_union(allStations,norStations[,c(1:4,43:45)]
allStations %>%
st_union(bslStations,mflStations) %>%
st_union(norStations) %>%
st_union(rrStations)
allStations <- st_union(bslStations[,c(1:4,43:45)],mflStations[,c(1:4,43:45)])
allStations <- st_union(allStations,norStations[,c(1:4,43:45)])
mapview(allStations)
allStations <- st_union(allStations,rrStations[,c(1:4,43:45)])
colnames(norStations)
colnames(bslStations)
allStations <- st_union(norStations[,c(1:4,50:52)], bslStations[,c(1:4,43:45)] )
colnames(mflStations)
allStations <- st_union(allStations,mflStations[,c(1:4,43:45)])
colnames(norStations)
colnames(rrStations)
allStations <- st_union(allStations,rrStations[,c(1:3,79:82)])
colnames(norStations)
createBuffer <- function(x) {
buffer <-
x[,c("OBJECTID","Route","Station","Latitude","Longitude","geometry")] %>%
st_transform(crs = 32618) %>% # projection
st_buffer(dist=804.672) %>% # this is 0.5 miles in meters
st_union() # make one shapefile of all buffers
}
norBuff <- createBuffer(norStations)
mapview(norBuff)
colnames(bslStations)
bslBuff <- createBuffer(bslStations)
mapview(bslBuff)
colnames(mflStations)
mflBuff <- createBuffer(mflStations)
mapview(mflBuff)
colnames(rrStations)
colnames(rrStations)[2] <- "Route"
colnames(rrStations)[3] <- "Station"
rrBuff <- createBuffer(rrStations)
mapview(rrBuff)
colnames(trolStations)
colnames(trolStations)
mapview(trolStations)
colnames(trolStations)[9] <- "Station"
trolBuff <- createBuffer(trolStations)
mapview(trolBuff)
colnames(busStations)
colnames(busStations)[9] <- "Station"
busBuff <- createBuffer(busStations)
mapview(busBuff)
allBuffs <- st_union(bslBuff,busBuff)
mapview(allBuffs)
allBuffs <-
st_union(bslBuff,busBuff) %>%
st_union(mflBuff) %>%
st_union(norBuff) %>%
st_union(rrBuff) %>%
st_union(trolBuff)
mapview(allBuffs)
geojson_write(input=allBuffs,file="transitPoly.geojson")
library(geojsonio)
geojson_write(input=allBuffs,file="transitPoly.geojson")
colnames(allBuffs)
str(allBuffs)
allBuffs  <- as(allBuffs, "Spatial")
mapview(allBuffs)
geojson_write(input=allBuffs,file="transitPoly.geojson")
str(allBuffs)
allBuffs  <- st_as_sf(allBuffs)
mapview(allBuffs)
geojson_write(input=allBuffs,file="transitPoly.geojson")
str(allBuffs)
str(bslStations)
str(bslBuff)
test <- st_coordinates(blsBuff)
test <- st_coordinates(bslBuff)
View(test)
str(norBuff)
createBuffer <- function(x) {
buffer <-
x[,c("OBJECTID","Route","Station","Latitude","Longitude","geometry")] %>%
#    st_transform(crs = 32618) %>% # projection
st_buffer(dist=804.672) %>% # this is 0.5 miles in meters
st_union() # make one shapefile of all buffers
}
colnames(norStations)
str(norStations)
norBuff <- createBuffer(norStations)
str(norBuff)
test <- st_sfc(norBuff)
str(test)
createBuffer <- function(x) {
buffer <-
x[,c("OBJECTID","Route","Station","Latitude","Longitude","geometry")] %>%
st_transform(crs = 4326) %>% # projection
st_buffer(dist=804.672) %>% # this is 0.5 miles in meters
st_union() # make one shapefile of all buffers
}
colnames(norStations)
str(norStations)
norBuff <- createBuffer(norStations)
createBuffer <- function(x) {
buffer <-
x[,c("OBJECTID","Route","Station","Latitude","Longitude","geometry")] %>%
st_transform(select(x,geometry), 4326) %>% # projection
st_buffer(dist=804.672) %>% # this is 0.5 miles in meters
st_union() # make one shapefile of all buffers
}
str(norStations)
norBuff <- createBuffer(norStations)
st_crs()
?st_crs()
createBuffer <- function(x) {
buffer <-
x[,c("OBJECTID","Route","Station","Latitude","Longitude","geometry")] %>%
st_transform(select(x,geometry), crs = 4326) %>% # projection
st_buffer(dist=804.672) %>% # this is 0.5 miles in meters
st_union() # make one shapefile of all buffers
}
norBuff <- createBuffer(norStations)
str(norBuff)
st_transform(norBuff, 3857)
st_proj_info()
st_proj_info("datum")
norStations
st_crs(x) <- "+proj=lcc +lat_1=40.66666666666666 +lat_2=41.03333333333333 +lat_0=40.16666666666666 +lon_0=-74 +x_0=300000 +y_0=0 +ellps=GRS80 +datum=NAD83 +to_meter=0.3048006096012192 +no_defs"
st_crs(norStations) <- "+proj=lcc +lat_1=40.66666666666666 +lat_2=41.03333333333333 +lat_0=40.16666666666666 +lon_0=-74 +x_0=300000 +y_0=0 +ellps=GRS80 +datum=NAD83 +to_meter=0.3048006096012192 +no_defs"
norStRepr <- st_transform(select(norStations,geometry),4326)
norStRepr
norStRepr <- st_transform(norStations,4326)
norStRepr
mapview(norStRepr)
mapview(norStations)
mapview(norBuff)
mapview(norStations)
st_crs(norStation)
st_crs(norStations)
st_crs(bslStations)
st_crs(allBuffs)
st_transform(allBuffs,st_crs(bslStations))
mapview(allBuffs)
geojson_write(input=allBuffs,file="transitPoly.geojson")
allBuffs <- st_transform(allBuffs,st_crs(bslStations))
mapview(allBuffs)
geojson_write(input=allBuffs,file="transitPoly.geojson")
censusKey <- "4d92e5c53d5b7046bae0b72874aceed0fde3e0b4"
walkscoreKey <-"a0a34de0dd2261f99677763bb3861e33"
setwd('/Users/amsr/Documents/GitHub/qapScoring-Final/data')
options(stringsAsFactors = FALSE)
censusKey <- "4d92e5c53d5b7046bae0b72874aceed0fde3e0b4"
walkscoreKey <-"a0a34de0dd2261f99677763bb3861e33"
hoods <- st_read("https://raw.githubusercontent.com/alisanroman/philly-hoods/master/data/Neighborhoods_Philadelphia.geojson")
allHoods <- read.csv('hoods.csv')
allHoods <- read.csv('csv/hoods.csv')
allHoods$mapname <- as.character(allHoods$mapname)
allHoods$planURL <- as.character(allHoods$planURL)
hoods2 <- merge(hoods,allHoods)
mapview(hoods2)
tracts <- st_read("https://raw.githubusercontent.com/alisanroman/qapScoring/master/data/Census_Tracts_2010.geojson")
cent<-  st_centroid(tracts)
hoodsTracts <- st_join(hoods2, cent)
hoodsTracts$mapname <- as.character(hoodsTracts$mapname)
ds_hoodsTracts <- data.frame(hoodsTracts) %>%
select("mapname","TRACTCE10","GEOID10")
mapview(hoodsTracts)
census_pull <- function(year,vars,stateFICS,county) {
final_url <- paste0("https://api.census.gov/data/",year,"/acs/acs5?get=",vars
,"&for=tract:*&in=state:",stateFICS,"&in=county:",county,"&key=",censusKey)
dat <- fromJSON(file = final_url)
d = ldply(dat)
colnames(d) <- d[1, ] # the first row will be the header
d = d[-1, ]          # removing the first row.
d <- unite(d,"GEOID10", c("state","county","tract"),sep="",remove=TRUE)
colNames <- colnames(d)
d[,colNames]<-lapply(d[,colNames],as.numeric)
d$GEOID10 <- as.factor(d$GEOID10)
d %>%
left_join(hoodsTracts,d,by='GEOID10')
}
test <- census_pull(year=2016
,vars = 'B17001_001E,B17001_002E,B25003_001E,B25003_002E'
,stateFICS = 42,county = 101)
library(geojsonio)
test <- census_pull(year=2016
,vars = 'B17001_001E,B17001_002E,B25003_001E,B25003_002E'
,stateFICS = 42,county = 101)
library(rjson)
test <- census_pull(year=2016
,vars = 'B17001_001E,B17001_002E,B25003_001E,B25003_002E'
,stateFICS = 42,county = 101)
library(plyr)
test <- census_pull(year=2016
,vars = 'B17001_001E,B17001_002E,B25003_001E,B25003_002E'
,stateFICS = 42,county = 101)
combo3 <- ddply(test, c("mapname"), summarise,
pop = sum(B17001_001E, na.rm = TRUE),
pov = sum(B17001_002E, na.rm = TRUE),
hhs = sum(B25003_001E, na.rm = TRUE),
hom = sum(B25003_002E,na.rm=TRUE))
combo3$povPct <- ifelse(combo3$pop != 0, as.numeric(round((combo3$pov / combo3$pop) * 100,1)), NA)
combo3$homPct <- ifelse(combo3$hhs != 0, as.numeric(round((combo3$hom / combo3$hhs) * 100,1)), NA)
polyData <- left_join(x=hoods2,y=combo3,by="mapname")
polyData <- subset(polyData,select = -c(cartodb_id,created_at,updated_at,name,listname))
polyData$lowPov <-  ifelse(polyData$povPct < 25.9,1,0)
polydata$ownerOcc <- ifelse(polyData$homPct >= 52.4, 1,0)
polyData$ownerOcc <- ifelse(polyData$homPct >= 52.4, 1,0)
geojson_write(input=censusData,file="censusData.geojson")
geojson_write(input=polyData,file="censusData.geojson")
View(polyData)
str(censusData)
str(polyData)
polyData$lowPov <-  ifelse(polyData$povPct < 25.9,'Yes','No')
polyData$ownerOcc <- ifelse(polyData$homPct >= 52.4,'Yes','No')
geojson_write(input=polyData,file="censusData.geojson")
View(polyData)
